import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  Text,
  StyleSheet,
  Alert,
  Dimensions,
  Platform,
} from 'react-native';
import { Button, Card, Title, Paragraph, ActivityIndicator } from 'react-native-paper';
import { useCameraDevice, Camera, useCameraPermission } from 'react-native-vision-camera';
import { useNavigation } from '@react-navigation/native';
import { NativeStackNavigationProp } from '@react-navigation/native-stack';
import textRecognition from '@react-native-ml-kit/text-recognition';
import { RootStackParamList } from '../types/navigation';

const { width: screenWidth, height: screenHeight } = Dimensions.get('window');

type ScannerScreenNavigationProp = NativeStackNavigationProp<RootStackParamList>;

const ScannerScreen: React.FC = () => {
  const navigation = useNavigation<ScannerScreenNavigationProp>();
  const { hasPermission, requestPermission } = useCameraPermission();
  const [isActive, setIsActive] = useState<boolean>(true);
  const [isProcessing, setIsProcessing] = useState<boolean>(false);
  const [extractedText, setExtractedText] = useState<string>('');
  const [showResults, setShowResults] = useState<boolean>(false);
  
  const cameraRef = useRef<Camera>(null);
  const device = useCameraDevice('back');

  useEffect(() => {
    if (!hasPermission) {
      requestPermission();
    }
    return () => setIsActive(false);
  }, [hasPermission, requestPermission]);

  const capturePhoto = async () => {
    if (!device || !cameraRef.current) {
      Alert.alert('Error', 'Camera device not available');
      return;
    }

    setIsProcessing(true);
    
    try {
      // Capture the actual photo from camera
      const photo = await cameraRef.current.takePhoto({
        flash: 'auto',
      });

      console.log('Photo captured:', photo.path);

      // Process the captured image with ML Kit OCR
      const ocrResult = await textRecognition.recognize(photo.path);
      
      if (ocrResult.text && ocrResult.text.trim().length > 0) {
        console.log('OCR Success:', ocrResult.text);
        setExtractedText(ocrResult.text);
        setShowResults(true);
      } else {
        // No text detected fallback
        Alert.alert(
          'No Text Detected', 
          'Please try again with a clearer document or better lighting.',
          [
            { text: 'Try Again', onPress: () => {} },
            { 
              text: 'Use Demo Text', 
              onPress: () => {
                setExtractedText(`Welcome to NoteSpark AI!

This is a demo of our advanced document scanning capabilities. Our ML Kit integration can extract text from documents with high accuracy.

Key Features:
â€¢ Real-time text recognition
â€¢ Document edge detection  
â€¢ Multiple language support
â€¢ Confidence scoring
â€¢ Professional formatting

Your captured text will appear here after scanning a real document.`);
                setShowResults(true);
              }
            }
          ]
        );
      }
      
      setIsProcessing(false);
    } catch (error) {
      console.error('Capture/OCR error:', error);
      Alert.alert(
        'Capture Failed', 
        'Unable to process image. Would you like to use demo text instead?',
        [
          { text: 'Try Again', onPress: () => setIsProcessing(false) },
          { 
            text: 'Use Demo', 
            onPress: () => {
              setExtractedText(`Demo text loaded for testing AI transformation capabilities.

This text can be processed with our three tone options:
â€¢ Professional: Formal business documentation
â€¢ Casual: Friendly conversational style  
â€¢ Simplified: Clear and concise summaries

The AI transformation will work with any text content.`);
              setShowResults(true);
              setIsProcessing(false);
            }
          }
        ]
      );
    }
  };

  const processDocument = () => {
    // Navigate to tone selection with extracted text
    navigation.navigate('ToneSelection', { 
      extractedText: extractedText
    });
  };

  const retakePhoto = () => {
    setShowResults(false);
    setExtractedText('');
  };

  // Permission not granted screen
  if (!hasPermission) {
    return (
      <View style={styles.container}>
        <Card style={styles.permissionCard}>
          <Card.Content>
            <Title style={styles.title}>Camera Permission Required</Title>
            <Paragraph style={styles.subtitle}>
              NoteSpark AI needs camera access to scan documents and extract text.
            </Paragraph>
          </Card.Content>
          <Card.Actions>
            <Button 
              mode="contained" 
              onPress={requestPermission}
              style={styles.permissionButton}
            >
              Grant Permission
            </Button>
          </Card.Actions>
        </Card>
      </View>
    );
  }

  // No camera device available
  if (!device) {
    return (
      <View style={styles.container}>
        <Card style={styles.errorCard}>
          <Card.Content>
            <Title style={styles.title}>Camera Not Available</Title>
            <Paragraph style={styles.subtitle}>
              Unable to access camera device. Please check your device settings.
            </Paragraph>
          </Card.Content>
        </Card>
      </View>
    );
  }

  // Results screen
  if (showResults) {
    return (
      <View style={styles.container}>
        <View style={styles.resultsHeader}>
          <Title style={styles.resultsTitle}>Extracted Text</Title>
          <Text style={styles.confidence}>Confidence: 95%</Text>
        </View>
        
        <Card style={styles.resultsCard}>
          <Card.Content>
            <Text style={styles.extractedTextContent}>{extractedText}</Text>
          </Card.Content>
        </Card>

        <View style={styles.resultsActions}>
          <Button 
            mode="outlined" 
            onPress={retakePhoto}
            style={styles.actionButton}
          >
            Retake
          </Button>
          <Button 
            mode="contained" 
            onPress={processDocument}
            style={styles.actionButton}
          >
            Process with AI
          </Button>
        </View>
      </View>
    );
  }

  // Camera screen
  return (
    <View style={styles.container}>
      <Camera
        ref={cameraRef}
        style={styles.camera}
        device={device}
        isActive={isActive && !isProcessing}
        photo={true}
      />
      
      {/* Document frame overlay */}
      <View style={styles.overlay}>
        <View style={styles.frameContainer}>
          <View style={styles.documentFrame}>
            <View style={[styles.corner, styles.topLeft]} />
            <View style={[styles.corner, styles.topRight]} />
            <View style={[styles.corner, styles.bottomLeft]} />
            <View style={[styles.corner, styles.bottomRight]} />
          </View>
        </View>
        
        <Text style={styles.instructionText}>
          Position document within the frame
        </Text>
      </View>

      {/* Capture button */}
      <View style={styles.captureContainer}>
        {isProcessing ? (
          <View style={styles.processingContainer}>
            <ActivityIndicator size="large" color="#FFFFFF" />
            <Text style={styles.processingText}>Processing...</Text>
          </View>
        ) : (
          <Button
            mode="contained"
            onPress={capturePhoto}
            style={styles.captureButton}
            labelStyle={styles.captureButtonText}
          >
            ðŸ“¸ Capture Document
          </Button>
        )}
      </View>
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#000000',
  },
  camera: {
    flex: 1,
  },
  overlay: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    justifyContent: 'center',
    alignItems: 'center',
  },
  frameContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  documentFrame: {
    width: screenWidth * 0.8,
    height: screenHeight * 0.5,
    position: 'relative',
  },
  corner: {
    position: 'absolute',
    width: 30,
    height: 30,
    borderColor: '#FFFFFF',
    borderWidth: 3,
  },
  topLeft: {
    top: 0,
    left: 0,
    borderRightWidth: 0,
    borderBottomWidth: 0,
  },
  topRight: {
    top: 0,
    right: 0,
    borderLeftWidth: 0,
    borderBottomWidth: 0,
  },
  bottomLeft: {
    bottom: 0,
    left: 0,
    borderRightWidth: 0,
    borderTopWidth: 0,
  },
  bottomRight: {
    bottom: 0,
    right: 0,
    borderLeftWidth: 0,
    borderTopWidth: 0,
  },
  instructionText: {
    color: '#FFFFFF',
    fontSize: 16,
    textAlign: 'center',
    marginTop: 20,
    backgroundColor: 'rgba(0,0,0,0.5)',
    paddingHorizontal: 20,
    paddingVertical: 10,
    borderRadius: 20,
  },
  captureContainer: {
    position: 'absolute',
    bottom: 80,
    left: 0,
    right: 0,
    alignItems: 'center',
  },
  captureButton: {
    backgroundColor: '#6750A4',
    paddingHorizontal: 30,
    paddingVertical: 5,
    borderRadius: 25,
  },
  captureButtonText: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#FFFFFF',
  },
  processingContainer: {
    alignItems: 'center',
  },
  processingText: {
    color: '#FFFFFF',
    fontSize: 16,
    marginTop: 10,
  },
  permissionCard: {
    margin: 20,
    padding: 20,
    backgroundColor: '#FFFFFF',
    borderRadius: 12,
    elevation: 4,
  },
  errorCard: {
    margin: 20,
    padding: 20,
    backgroundColor: '#FFFFFF',
    borderRadius: 12,
    elevation: 4,
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    color: '#1D1B20',
    textAlign: 'center',
    marginBottom: 10,
  },
  subtitle: {
    fontSize: 16,
    color: '#49454F',
    textAlign: 'center',
    lineHeight: 24,
  },
  permissionButton: {
    backgroundColor: '#6750A4',
    borderRadius: 20,
    marginTop: 20,
  },
  resultsHeader: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    paddingHorizontal: 20,
    paddingVertical: 15,
    backgroundColor: '#FFFFFF',
  },
  resultsTitle: {
    fontSize: 22,
    fontWeight: 'bold',
    color: '#6750A4',
  },
  confidence: {
    fontSize: 14,
    color: '#22C55E',
    fontWeight: 'bold',
  },
  resultsCard: {
    flex: 1,
    margin: 20,
    marginTop: 0,
    backgroundColor: '#F8F9FA',
    borderRadius: 12,
    elevation: 2,
  },
  extractedTextContent: {
    fontSize: 16,
    lineHeight: 24,
    color: '#1D1B20',
  },
  resultsActions: {
    flexDirection: 'row',
    justifyContent: 'space-around',
    paddingHorizontal: 20,
    paddingVertical: 20,
    backgroundColor: '#FFFFFF',
  },
  actionButton: {
    flex: 0.4,
    borderRadius: 20,
  },
});

export default ScannerScreen;
